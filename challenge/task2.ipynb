{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9ZmxP6StAoz"
   },
   "source": [
    "# CS542 - Class Challenge - fine-grained classification of plants:\n",
    "\n",
    "Our class challenge will consists of two tasks addressing an image recognition task where our dataset contains about 1K categories of plants with only about 250,000 images.  There will be two parts to this task:\n",
    "\n",
    "1. Image classification. Imagine we have cateloged all the plants we care to identify, now we just need to create a classifier for them! Use your skills from the supervised learning sections of this course to try to address this problem.\n",
    "\n",
    "2. Semi-Supervised/Few-Shot Learning.  Unfortunately, we missed some important plants we want to classify!  We do have some images we think contain the plant, but we have only have a few labels.  Our new goal is to develop an AI model that can learn from just these labeled examples.\n",
    "\n",
    "Each student must submit a model on both tasks.  Students in the top 3 on each task will get 5% extra credit on this assignment.\n",
    "\n",
    "This notebook is associated with the first task (image classification).\n",
    "\n",
    "\n",
    "# Dataset\n",
    "The dataset is downloaded on scc in the address: \"/projectnb2/cs542-bap/classChallenge/data\". You can find the python version of this notebook there as well or you could just type \"jupyter nbconvert --to script baselineModel_task1.ipynb\" and it will output \"baselineModel_task1.py\". You should be able to run \"baselineModel_task1.py\" on scc by simply typing \"python baselineModel_task1.py\"\n",
    "\n",
    "Please don't try to change or delete the dataset.\n",
    "\n",
    "# Evaluation:\n",
    "You will compete with each other over your performance on the dedicated test set. The performance measure is top the 5 error, i.e: if the true class is in one of your top 5 likely predictions, then its error is 0, otherwise its error is 1.  So, your goal is to get an error of 0. This notebook outputs top5 accuracy, so it is 1 - top5 error.\n",
    "\n",
    "# Baseline:\n",
    "The following code is a baseline which you can use and improve to come up with your model for this task\n",
    "\n",
    "# Suggestion\n",
    "One simple suggestion would be to use a pretrained model on imagenet and finetune it on this data similar to this [link](https://keras.io/api/applications/)\n",
    "Also you should likely train more than 2 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4q8oub7ntAo1"
   },
   "source": [
    "## Import TensorFlow and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "14D2EZ17tAo1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "1\n",
      "NUM CORES:  16\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(os.getenv(\"CUDA_VISIBLE_DEVICES\"))\n",
    "tf.config.set_soft_device_placement(True)\n",
    "def get_n_cores():\n",
    "  nslots = os.getenv('NSLOTS')\n",
    "  if nslots is not None:\n",
    "    return int(nslots)\n",
    "  raise ValueError('Environment variable NSLOTS is not defined.')\n",
    "print(\"NUM CORES: \", get_n_cores())\n",
    "tf.config.threading.set_intra_op_parallelism_threads(get_n_cores()-1)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYaBUsR-tAo3"
   },
   "source": [
    "# Create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "m893cNgztAo3"
   },
   "outputs": [],
   "source": [
    "data_dir = '/projectnb2/cs542-bap/class_challenge/'\n",
    "\n",
    "train_ds = tf.data.TextLineDataset(os.path.join(data_dir, 'train_held_out_labeled.txt'))\n",
    "train_unlabeled_ds = tf.data.TextLineDataset(os.path.join(data_dir, 'train_held_out.txt'))\n",
    "val_ds = tf.data.TextLineDataset(os.path.join(data_dir, 'val_held_out.txt'))\n",
    "test_ds = tf.data.TextLineDataset(os.path.join(data_dir, 'test_held_out.txt'))\n",
    "\n",
    "with open(os.path.join(data_dir, 'classes_held_out.txt'), 'r') as f:\n",
    "  class_names = [c.strip() for c in f.readlines()]\n",
    "\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2m6getXwtAo3"
   },
   "source": [
    "## Write a short function that converts a file path to an (img, label) pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZrIrN5iItAo3"
   },
   "outputs": [],
   "source": [
    "def decode_img(img, crop_size=224):\n",
    "    img = tf.io.read_file(img)\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # resize the image to the desired size\n",
    "    return tf.image.resize(img, [crop_size, crop_size])\n",
    "\n",
    "def get_label(label):\n",
    "    # find teh matching label\n",
    "    one_hot = tf.where(tf.equal(label, class_names))\n",
    "    # Integer encode the label\n",
    "    return tf.reduce_min(one_hot)\n",
    "\n",
    "def process_path(file_path):\n",
    "    # should have two parts\n",
    "    file_path = tf.strings.split(file_path)\n",
    "    # second part has the class index\n",
    "    label = get_label(file_path[1])\n",
    "    # load the raw data from the file\n",
    "    img = decode_img(tf.strings.join([data_dir, 'images/', file_path[0], '.jpg']))\n",
    "    return img, label\n",
    "\n",
    "def process_path_test(file_path):\n",
    "    # load the raw data from the file\n",
    "    img = decode_img(tf.strings.join([data_dir, 'images/', file_path, '.jpg']))\n",
    "    return img, file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBUt-k32tAo3"
   },
   "source": [
    "## Finish setting up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9GWelLTntAo3"
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hD7gOwX0tAo3"
   },
   "outputs": [],
   "source": [
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "train_unlabeled_ds = train_unlabeled_ds.map(process_path_test, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "test_ds = test_ds.map(process_path_test, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epSS5nlYtAo3"
   },
   "source": [
    "## Data loader hyper-parameters for performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "oIrk9SuYtAo3"
   },
   "outputs": [],
   "source": [
    "def configure_for_performance(ds):\n",
    "  ds = ds.cache()\n",
    "  ds = ds.shuffle(buffer_size=1000)\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "  return ds\n",
    "\n",
    "train_ds = configure_for_performance(train_ds)\n",
    "train_unlabeled_ds = configure_for_performance(train_unlabeled_ds)\n",
    "val_ds = configure_for_performance(val_ds)\n",
    "test_ds = configure_for_performance(test_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyOA90IRtAo4"
   },
   "source": [
    "## A simple CNN model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wWHpzQoatAo4"
   },
   "outputs": [],
   "source": [
    "#DenseNet201 with initial imagenet weights, no top layers, global max pooling\n",
    "\n",
    "DenseNet = tf.keras.applications.DenseNet201(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224,224,3),\n",
    "    pooling='max',\n",
    ")\n",
    "\n",
    "#data augmentation layers\n",
    "data_aug = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomFlip(mode='horizontal'),\n",
    "    layers.experimental.preprocessing.RandomTranslation(.2, .2, fill_mode='wrap'),\n",
    "    layers.experimental.preprocessing.RandomContrast(.1),\n",
    "    layers.experimental.preprocessing.RandomRotation(.2),\n",
    "    layers.experimental.preprocessing.RandomZoom(.3)])\n",
    "\n",
    "#model\n",
    "model = tf.keras.Sequential([\n",
    "    data_aug, \n",
    "    DenseNet,\n",
    "    layers.Dropout(.5), \n",
    "    layers.Dense(num_classes)\n",
    "])\n",
    "inputs = layers.Input([None, None, 3], dtype=tf.uint8)\n",
    "outputs = tf.cast(inputs, tf.float32)\n",
    "\n",
    "#DenseNet data preprocessing\n",
    "outputs = tf.keras.applications.densenet.preprocess_input(outputs)\n",
    "\n",
    "outputs = model(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5CFFrdvMtAo4"
   },
   "source": [
    "## The usual loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MaUMyxl3tAo4"
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=.0001, amsgrad=True)\n",
    "model.compile(\n",
    "  optimizer=opt,\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy',tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYePw6F3tAo4"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BEi56DBrtAo4",
    "outputId": "c562c07e-79eb-4c1a-8dc4-41ee9f877263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 6s 1s/step - loss: 10.9413 - accuracy: 0.0500 - sparse_top_k_categorical_accuracy: 0.2100 - val_loss: 6.8611 - val_accuracy: 0.0611 - val_sparse_top_k_categorical_accuracy: 0.2426\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 2s 399ms/step - loss: 9.4985 - accuracy: 0.1200 - sparse_top_k_categorical_accuracy: 0.2700 - val_loss: 6.0676 - val_accuracy: 0.0776 - val_sparse_top_k_categorical_accuracy: 0.2739\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 2s 399ms/step - loss: 7.3496 - accuracy: 0.1100 - sparse_top_k_categorical_accuracy: 0.4300 - val_loss: 5.4650 - val_accuracy: 0.0974 - val_sparse_top_k_categorical_accuracy: 0.3218\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 2s 400ms/step - loss: 6.5949 - accuracy: 0.1100 - sparse_top_k_categorical_accuracy: 0.4600 - val_loss: 4.9283 - val_accuracy: 0.1106 - val_sparse_top_k_categorical_accuracy: 0.3944\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 2s 398ms/step - loss: 5.4416 - accuracy: 0.1900 - sparse_top_k_categorical_accuracy: 0.5300 - val_loss: 4.4218 - val_accuracy: 0.1287 - val_sparse_top_k_categorical_accuracy: 0.4587\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 2s 397ms/step - loss: 4.5160 - accuracy: 0.3400 - sparse_top_k_categorical_accuracy: 0.6500 - val_loss: 3.9891 - val_accuracy: 0.1700 - val_sparse_top_k_categorical_accuracy: 0.5099\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 2s 397ms/step - loss: 4.3646 - accuracy: 0.3300 - sparse_top_k_categorical_accuracy: 0.6500 - val_loss: 3.6409 - val_accuracy: 0.2228 - val_sparse_top_k_categorical_accuracy: 0.5578\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 2s 399ms/step - loss: 3.7479 - accuracy: 0.3700 - sparse_top_k_categorical_accuracy: 0.7500 - val_loss: 3.3502 - val_accuracy: 0.2822 - val_sparse_top_k_categorical_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 2s 389ms/step - loss: 3.4701 - accuracy: 0.4500 - sparse_top_k_categorical_accuracy: 0.7400 - val_loss: 3.1354 - val_accuracy: 0.3086 - val_sparse_top_k_categorical_accuracy: 0.6238\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 2s 389ms/step - loss: 3.6466 - accuracy: 0.3300 - sparse_top_k_categorical_accuracy: 0.7000 - val_loss: 2.9722 - val_accuracy: 0.3432 - val_sparse_top_k_categorical_accuracy: 0.6518\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 2s 397ms/step - loss: 2.6823 - accuracy: 0.5100 - sparse_top_k_categorical_accuracy: 0.8300 - val_loss: 2.8383 - val_accuracy: 0.3828 - val_sparse_top_k_categorical_accuracy: 0.6535\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 2s 395ms/step - loss: 2.6678 - accuracy: 0.5000 - sparse_top_k_categorical_accuracy: 0.8200 - val_loss: 2.7332 - val_accuracy: 0.3878 - val_sparse_top_k_categorical_accuracy: 0.6749\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 2s 389ms/step - loss: 2.6457 - accuracy: 0.4900 - sparse_top_k_categorical_accuracy: 0.8400 - val_loss: 2.6306 - val_accuracy: 0.4142 - val_sparse_top_k_categorical_accuracy: 0.6947\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 2s 386ms/step - loss: 1.9921 - accuracy: 0.5300 - sparse_top_k_categorical_accuracy: 0.8600 - val_loss: 2.5429 - val_accuracy: 0.4422 - val_sparse_top_k_categorical_accuracy: 0.7112\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 2s 387ms/step - loss: 1.6992 - accuracy: 0.6200 - sparse_top_k_categorical_accuracy: 0.8900 - val_loss: 2.4670 - val_accuracy: 0.4620 - val_sparse_top_k_categorical_accuracy: 0.7244\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 2s 393ms/step - loss: 2.1626 - accuracy: 0.5700 - sparse_top_k_categorical_accuracy: 0.8700 - val_loss: 2.3958 - val_accuracy: 0.4752 - val_sparse_top_k_categorical_accuracy: 0.7459\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 2s 401ms/step - loss: 1.5309 - accuracy: 0.6800 - sparse_top_k_categorical_accuracy: 0.9200 - val_loss: 2.3447 - val_accuracy: 0.4719 - val_sparse_top_k_categorical_accuracy: 0.7657\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 2s 400ms/step - loss: 1.6670 - accuracy: 0.5800 - sparse_top_k_categorical_accuracy: 0.8900 - val_loss: 2.3125 - val_accuracy: 0.4620 - val_sparse_top_k_categorical_accuracy: 0.7838\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 2s 387ms/step - loss: 1.5285 - accuracy: 0.6000 - sparse_top_k_categorical_accuracy: 0.9400 - val_loss: 2.2955 - val_accuracy: 0.4637 - val_sparse_top_k_categorical_accuracy: 0.7904\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 2s 389ms/step - loss: 0.9408 - accuracy: 0.7300 - sparse_top_k_categorical_accuracy: 0.9400 - val_loss: 2.3051 - val_accuracy: 0.4620 - val_sparse_top_k_categorical_accuracy: 0.8003\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 2s 384ms/step - loss: 1.1485 - accuracy: 0.6800 - sparse_top_k_categorical_accuracy: 0.9500 - val_loss: 2.3446 - val_accuracy: 0.4719 - val_sparse_top_k_categorical_accuracy: 0.8086\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 2s 384ms/step - loss: 1.4385 - accuracy: 0.6800 - sparse_top_k_categorical_accuracy: 0.9300 - val_loss: 2.4083 - val_accuracy: 0.4653 - val_sparse_top_k_categorical_accuracy: 0.8152\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 2s 398ms/step - loss: 0.8146 - accuracy: 0.7800 - sparse_top_k_categorical_accuracy: 0.9300 - val_loss: 2.4490 - val_accuracy: 0.4785 - val_sparse_top_k_categorical_accuracy: 0.8119\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 2s 397ms/step - loss: 0.9755 - accuracy: 0.7400 - sparse_top_k_categorical_accuracy: 0.9700 - val_loss: 2.4692 - val_accuracy: 0.4769 - val_sparse_top_k_categorical_accuracy: 0.8168\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 2s 403ms/step - loss: 1.1096 - accuracy: 0.7300 - sparse_top_k_categorical_accuracy: 0.9700 - val_loss: 2.4757 - val_accuracy: 0.4868 - val_sparse_top_k_categorical_accuracy: 0.8201\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 2s 402ms/step - loss: 1.2817 - accuracy: 0.7200 - sparse_top_k_categorical_accuracy: 0.9300 - val_loss: 2.4746 - val_accuracy: 0.4950 - val_sparse_top_k_categorical_accuracy: 0.8234\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 2s 402ms/step - loss: 0.5632 - accuracy: 0.8500 - sparse_top_k_categorical_accuracy: 0.9800 - val_loss: 2.4224 - val_accuracy: 0.5050 - val_sparse_top_k_categorical_accuracy: 0.8267\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 2s 400ms/step - loss: 0.6648 - accuracy: 0.8700 - sparse_top_k_categorical_accuracy: 0.9700 - val_loss: 2.3941 - val_accuracy: 0.5231 - val_sparse_top_k_categorical_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 2s 396ms/step - loss: 0.6004 - accuracy: 0.8700 - sparse_top_k_categorical_accuracy: 0.9700 - val_loss: 2.3689 - val_accuracy: 0.5297 - val_sparse_top_k_categorical_accuracy: 0.8284\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 2s 382ms/step - loss: 0.4617 - accuracy: 0.8300 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.3293 - val_accuracy: 0.5314 - val_sparse_top_k_categorical_accuracy: 0.8284\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 2s 381ms/step - loss: 0.7308 - accuracy: 0.8200 - sparse_top_k_categorical_accuracy: 0.9700 - val_loss: 2.2893 - val_accuracy: 0.5413 - val_sparse_top_k_categorical_accuracy: 0.8366\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 2s 384ms/step - loss: 0.4152 - accuracy: 0.8600 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.2843 - val_accuracy: 0.5512 - val_sparse_top_k_categorical_accuracy: 0.8465\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 2s 395ms/step - loss: 0.5697 - accuracy: 0.8300 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.2558 - val_accuracy: 0.5660 - val_sparse_top_k_categorical_accuracy: 0.8531\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 2s 394ms/step - loss: 0.5441 - accuracy: 0.8500 - sparse_top_k_categorical_accuracy: 0.9600 - val_loss: 2.2418 - val_accuracy: 0.5759 - val_sparse_top_k_categorical_accuracy: 0.8581\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 2s 400ms/step - loss: 0.5165 - accuracy: 0.8800 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.2176 - val_accuracy: 0.5891 - val_sparse_top_k_categorical_accuracy: 0.8531\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 397ms/step - loss: 0.3335 - accuracy: 0.9200 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.1881 - val_accuracy: 0.6007 - val_sparse_top_k_categorical_accuracy: 0.8581\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 2s 395ms/step - loss: 0.2525 - accuracy: 0.9000 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.1961 - val_accuracy: 0.5990 - val_sparse_top_k_categorical_accuracy: 0.8597\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 2s 396ms/step - loss: 0.3545 - accuracy: 0.9000 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.2256 - val_accuracy: 0.5908 - val_sparse_top_k_categorical_accuracy: 0.8630\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 2s 397ms/step - loss: 0.5075 - accuracy: 0.8800 - sparse_top_k_categorical_accuracy: 0.9800 - val_loss: 2.2358 - val_accuracy: 0.5842 - val_sparse_top_k_categorical_accuracy: 0.8597\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 2s 399ms/step - loss: 0.2209 - accuracy: 0.9200 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.2355 - val_accuracy: 0.5891 - val_sparse_top_k_categorical_accuracy: 0.8564\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 2s 383ms/step - loss: 0.3721 - accuracy: 0.9400 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.3300 - val_accuracy: 0.5825 - val_sparse_top_k_categorical_accuracy: 0.8564\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 2s 396ms/step - loss: 0.2275 - accuracy: 0.9400 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.4282 - val_accuracy: 0.5842 - val_sparse_top_k_categorical_accuracy: 0.8465\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 2s 395ms/step - loss: 0.2636 - accuracy: 0.9300 - sparse_top_k_categorical_accuracy: 0.9800 - val_loss: 2.5298 - val_accuracy: 0.5743 - val_sparse_top_k_categorical_accuracy: 0.8432\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 2s 400ms/step - loss: 0.2357 - accuracy: 0.9000 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.6351 - val_accuracy: 0.5776 - val_sparse_top_k_categorical_accuracy: 0.8432\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 2s 394ms/step - loss: 0.4064 - accuracy: 0.9100 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.7498 - val_accuracy: 0.5776 - val_sparse_top_k_categorical_accuracy: 0.8399\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 2s 395ms/step - loss: 0.2400 - accuracy: 0.9500 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.8726 - val_accuracy: 0.5545 - val_sparse_top_k_categorical_accuracy: 0.8350\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 2s 395ms/step - loss: 0.1823 - accuracy: 0.9200 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.9739 - val_accuracy: 0.5495 - val_sparse_top_k_categorical_accuracy: 0.8416\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 2s 398ms/step - loss: 0.3943 - accuracy: 0.8800 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 3.0954 - val_accuracy: 0.5578 - val_sparse_top_k_categorical_accuracy: 0.8416\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 2s 395ms/step - loss: 0.3283 - accuracy: 0.8700 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 3.0814 - val_accuracy: 0.5578 - val_sparse_top_k_categorical_accuracy: 0.8482\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 2s 398ms/step - loss: 0.2886 - accuracy: 0.9100 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.9367 - val_accuracy: 0.5594 - val_sparse_top_k_categorical_accuracy: 0.8531\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 2s 396ms/step - loss: 0.3860 - accuracy: 0.8600 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.8338 - val_accuracy: 0.5743 - val_sparse_top_k_categorical_accuracy: 0.8564\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 2s 395ms/step - loss: 0.4523 - accuracy: 0.8900 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.6920 - val_accuracy: 0.5941 - val_sparse_top_k_categorical_accuracy: 0.8597\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 2s 395ms/step - loss: 0.3531 - accuracy: 0.8900 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.5301 - val_accuracy: 0.6056 - val_sparse_top_k_categorical_accuracy: 0.8614\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 2s 396ms/step - loss: 0.2283 - accuracy: 0.9400 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.4053 - val_accuracy: 0.6172 - val_sparse_top_k_categorical_accuracy: 0.8647\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 2s 395ms/step - loss: 0.3020 - accuracy: 0.9000 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.3484 - val_accuracy: 0.6155 - val_sparse_top_k_categorical_accuracy: 0.8696\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 2s 390ms/step - loss: 0.1614 - accuracy: 0.9400 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.3298 - val_accuracy: 0.5990 - val_sparse_top_k_categorical_accuracy: 0.8729\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 2s 383ms/step - loss: 0.2282 - accuracy: 0.9200 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.4837 - val_accuracy: 0.6007 - val_sparse_top_k_categorical_accuracy: 0.8762\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 2s 383ms/step - loss: 0.1639 - accuracy: 0.9400 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.5612 - val_accuracy: 0.5941 - val_sparse_top_k_categorical_accuracy: 0.8696\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 2s 384ms/step - loss: 0.2460 - accuracy: 0.9300 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.5492 - val_accuracy: 0.5990 - val_sparse_top_k_categorical_accuracy: 0.8729\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 2s 393ms/step - loss: 0.1642 - accuracy: 0.9500 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.5210 - val_accuracy: 0.6056 - val_sparse_top_k_categorical_accuracy: 0.8795\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 2s 381ms/step - loss: 0.2490 - accuracy: 0.9000 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.5202 - val_accuracy: 0.6089 - val_sparse_top_k_categorical_accuracy: 0.8729\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 2s 408ms/step - loss: 0.2788 - accuracy: 0.9300 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.5006 - val_accuracy: 0.6172 - val_sparse_top_k_categorical_accuracy: 0.8729\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 2s 395ms/step - loss: 0.0954 - accuracy: 0.9500 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.5017 - val_accuracy: 0.6155 - val_sparse_top_k_categorical_accuracy: 0.8663\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 2s 396ms/step - loss: 0.2105 - accuracy: 0.9300 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.5021 - val_accuracy: 0.6254 - val_sparse_top_k_categorical_accuracy: 0.8630\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 2s 383ms/step - loss: 0.2766 - accuracy: 0.9300 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.5067 - val_accuracy: 0.6188 - val_sparse_top_k_categorical_accuracy: 0.8597\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 2s 383ms/step - loss: 0.2417 - accuracy: 0.9500 - sparse_top_k_categorical_accuracy: 0.9800 - val_loss: 2.5733 - val_accuracy: 0.6122 - val_sparse_top_k_categorical_accuracy: 0.8597\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 2s 382ms/step - loss: 0.2425 - accuracy: 0.9400 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.5886 - val_accuracy: 0.6073 - val_sparse_top_k_categorical_accuracy: 0.8581\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 2s 383ms/step - loss: 0.3133 - accuracy: 0.9100 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.5892 - val_accuracy: 0.6139 - val_sparse_top_k_categorical_accuracy: 0.8581\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 2s 392ms/step - loss: 0.2215 - accuracy: 0.9100 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.5843 - val_accuracy: 0.6139 - val_sparse_top_k_categorical_accuracy: 0.8696\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 2s 390ms/step - loss: 0.1944 - accuracy: 0.9400 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.5985 - val_accuracy: 0.5990 - val_sparse_top_k_categorical_accuracy: 0.8696\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 386ms/step - loss: 0.1895 - accuracy: 0.9500 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.6139 - val_accuracy: 0.5990 - val_sparse_top_k_categorical_accuracy: 0.8680\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 2s 385ms/step - loss: 0.1498 - accuracy: 0.9500 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.6528 - val_accuracy: 0.6073 - val_sparse_top_k_categorical_accuracy: 0.8630\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 2s 384ms/step - loss: 0.0660 - accuracy: 0.9800 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.6334 - val_accuracy: 0.6139 - val_sparse_top_k_categorical_accuracy: 0.8696\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 2s 383ms/step - loss: 0.1073 - accuracy: 0.9400 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.6083 - val_accuracy: 0.6073 - val_sparse_top_k_categorical_accuracy: 0.8663\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 2s 382ms/step - loss: 0.2250 - accuracy: 0.9700 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.5765 - val_accuracy: 0.6040 - val_sparse_top_k_categorical_accuracy: 0.8696\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 2s 382ms/step - loss: 0.0573 - accuracy: 0.9900 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.5457 - val_accuracy: 0.6089 - val_sparse_top_k_categorical_accuracy: 0.8746\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 2s 389ms/step - loss: 0.1558 - accuracy: 0.9400 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.5562 - val_accuracy: 0.6089 - val_sparse_top_k_categorical_accuracy: 0.8795\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 2s 384ms/step - loss: 0.0638 - accuracy: 0.9800 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.5431 - val_accuracy: 0.6040 - val_sparse_top_k_categorical_accuracy: 0.8779\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 2s 384ms/step - loss: 0.0833 - accuracy: 0.9700 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.4952 - val_accuracy: 0.6122 - val_sparse_top_k_categorical_accuracy: 0.8845\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 2s 382ms/step - loss: 0.1170 - accuracy: 0.9700 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.5000 - val_accuracy: 0.6188 - val_sparse_top_k_categorical_accuracy: 0.8779\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 2s 386ms/step - loss: 0.1567 - accuracy: 0.9500 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.5215 - val_accuracy: 0.6205 - val_sparse_top_k_categorical_accuracy: 0.8828\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 2s 384ms/step - loss: 0.1936 - accuracy: 0.9400 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.5080 - val_accuracy: 0.6188 - val_sparse_top_k_categorical_accuracy: 0.8878\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 2s 384ms/step - loss: 0.1824 - accuracy: 0.9700 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.5846 - val_accuracy: 0.6205 - val_sparse_top_k_categorical_accuracy: 0.8861\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 2s 384ms/step - loss: 0.1595 - accuracy: 0.9700 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.6258 - val_accuracy: 0.6221 - val_sparse_top_k_categorical_accuracy: 0.8878\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 2s 386ms/step - loss: 0.1006 - accuracy: 0.9600 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.6116 - val_accuracy: 0.6188 - val_sparse_top_k_categorical_accuracy: 0.8845\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 2s 386ms/step - loss: 0.1207 - accuracy: 0.9700 - sparse_top_k_categorical_accuracy: 0.9900 - val_loss: 2.6597 - val_accuracy: 0.6221 - val_sparse_top_k_categorical_accuracy: 0.8828\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 2s 384ms/step - loss: 0.1759 - accuracy: 0.9500 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.6301 - val_accuracy: 0.6188 - val_sparse_top_k_categorical_accuracy: 0.8911\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 2s 388ms/step - loss: 0.0854 - accuracy: 0.9600 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.5612 - val_accuracy: 0.6155 - val_sparse_top_k_categorical_accuracy: 0.8911\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 2s 388ms/step - loss: 0.0455 - accuracy: 0.9700 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.4953 - val_accuracy: 0.6287 - val_sparse_top_k_categorical_accuracy: 0.8977\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 2s 382ms/step - loss: 0.0692 - accuracy: 0.9800 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.4543 - val_accuracy: 0.6271 - val_sparse_top_k_categorical_accuracy: 0.8944\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 2s 382ms/step - loss: 0.0181 - accuracy: 0.9900 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.4263 - val_accuracy: 0.6254 - val_sparse_top_k_categorical_accuracy: 0.8927\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 2s 382ms/step - loss: 0.0681 - accuracy: 0.9800 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.4537 - val_accuracy: 0.6337 - val_sparse_top_k_categorical_accuracy: 0.8927\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 2s 382ms/step - loss: 0.1392 - accuracy: 0.9500 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.3926 - val_accuracy: 0.6419 - val_sparse_top_k_categorical_accuracy: 0.8911\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 2s 381ms/step - loss: 0.1260 - accuracy: 0.9700 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.2676 - val_accuracy: 0.6502 - val_sparse_top_k_categorical_accuracy: 0.8944\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 2s 385ms/step - loss: 0.0087 - accuracy: 1.0000 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.2054 - val_accuracy: 0.6518 - val_sparse_top_k_categorical_accuracy: 0.8944\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 2s 382ms/step - loss: 0.0356 - accuracy: 0.9800 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.1745 - val_accuracy: 0.6502 - val_sparse_top_k_categorical_accuracy: 0.9010\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 2s 383ms/step - loss: 0.0152 - accuracy: 1.0000 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.1659 - val_accuracy: 0.6551 - val_sparse_top_k_categorical_accuracy: 0.9026\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 2s 384ms/step - loss: 0.2116 - accuracy: 0.9700 - sparse_top_k_categorical_accuracy: 0.9800 - val_loss: 2.1390 - val_accuracy: 0.6535 - val_sparse_top_k_categorical_accuracy: 0.8960\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 2s 384ms/step - loss: 0.0631 - accuracy: 0.9800 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.1160 - val_accuracy: 0.6535 - val_sparse_top_k_categorical_accuracy: 0.8977\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 2s 384ms/step - loss: 0.0842 - accuracy: 0.9900 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.1005 - val_accuracy: 0.6452 - val_sparse_top_k_categorical_accuracy: 0.8878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b2cac1c67f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds,validation_data=val_ds,epochs=100,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add predictions of unlabeled data to labeled data and retrain\n",
    "\n",
    "#copy data to a temp file to append predicted labels to\n",
    "with open(os.path.join(data_dir, 'train_held_out_labeled.txt')) as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [l for l in lines if \"ROW\" in l]\n",
    "    with open(\"train_with_labeled_data.txt\", \"w\") as f1:\n",
    "        f1.writelines(lines)\n",
    "\n",
    "#append predicted labels with high confidence to train dataset\n",
    "trained_model = model\n",
    "with open('train_with_labeled_data.txt', 'a') as f:\n",
    "    for image_batch, image_names in train_unlabeled_ds:\n",
    "        for image_name, predictions in zip(image_names.numpy(), trained_model.predict(image_batch)):\n",
    "            inds = np.argmax(predictions)\n",
    "            if predictions[inds] > .9:\n",
    "                line = str(int(image_name)) + ' ' + class_names[inds]\n",
    "                f.write(line + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 32s 240ms/step - loss: 2.0412 - accuracy: 0.6153 - sparse_top_k_categorical_accuracy: 0.8916 - val_loss: 3.9467 - val_accuracy: 0.6205 - val_sparse_top_k_categorical_accuracy: 0.8977\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 28s 209ms/step - loss: 1.5484 - accuracy: 0.6492 - sparse_top_k_categorical_accuracy: 0.9166 - val_loss: 1.7480 - val_accuracy: 0.6568 - val_sparse_top_k_categorical_accuracy: 0.9191\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 28s 209ms/step - loss: 1.2370 - accuracy: 0.6904 - sparse_top_k_categorical_accuracy: 0.9337 - val_loss: 1.6436 - val_accuracy: 0.6419 - val_sparse_top_k_categorical_accuracy: 0.9307\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 28s 210ms/step - loss: 1.0783 - accuracy: 0.7267 - sparse_top_k_categorical_accuracy: 0.9451 - val_loss: 1.7171 - val_accuracy: 0.6452 - val_sparse_top_k_categorical_accuracy: 0.9274\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.9953 - accuracy: 0.7241 - sparse_top_k_categorical_accuracy: 0.9541 - val_loss: 1.4935 - val_accuracy: 0.6485 - val_sparse_top_k_categorical_accuracy: 0.9175\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.8756 - accuracy: 0.7569 - sparse_top_k_categorical_accuracy: 0.9632 - val_loss: 1.5533 - val_accuracy: 0.6584 - val_sparse_top_k_categorical_accuracy: 0.9241\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.8032 - accuracy: 0.7735 - sparse_top_k_categorical_accuracy: 0.9705 - val_loss: 1.7610 - val_accuracy: 0.6452 - val_sparse_top_k_categorical_accuracy: 0.9323\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.7967 - accuracy: 0.7726 - sparse_top_k_categorical_accuracy: 0.9667 - val_loss: 1.4041 - val_accuracy: 0.6700 - val_sparse_top_k_categorical_accuracy: 0.9340\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.6882 - accuracy: 0.7940 - sparse_top_k_categorical_accuracy: 0.9734 - val_loss: 1.6642 - val_accuracy: 0.6469 - val_sparse_top_k_categorical_accuracy: 0.9323\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 28s 209ms/step - loss: 0.6233 - accuracy: 0.8130 - sparse_top_k_categorical_accuracy: 0.9815 - val_loss: 1.3290 - val_accuracy: 0.6832 - val_sparse_top_k_categorical_accuracy: 0.9422\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 28s 208ms/step - loss: 0.6528 - accuracy: 0.8080 - sparse_top_k_categorical_accuracy: 0.9784 - val_loss: 1.7249 - val_accuracy: 0.6667 - val_sparse_top_k_categorical_accuracy: 0.9323\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.5771 - accuracy: 0.8234 - sparse_top_k_categorical_accuracy: 0.9822 - val_loss: 1.6195 - val_accuracy: 0.6650 - val_sparse_top_k_categorical_accuracy: 0.9340\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.5415 - accuracy: 0.8334 - sparse_top_k_categorical_accuracy: 0.9841 - val_loss: 1.5726 - val_accuracy: 0.6749 - val_sparse_top_k_categorical_accuracy: 0.9290\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.5107 - accuracy: 0.8360 - sparse_top_k_categorical_accuracy: 0.9855 - val_loss: 1.4382 - val_accuracy: 0.6782 - val_sparse_top_k_categorical_accuracy: 0.9422\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 27s 207ms/step - loss: 0.4680 - accuracy: 0.8548 - sparse_top_k_categorical_accuracy: 0.9869 - val_loss: 1.6058 - val_accuracy: 0.6535 - val_sparse_top_k_categorical_accuracy: 0.9373\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.4668 - accuracy: 0.8569 - sparse_top_k_categorical_accuracy: 0.9872 - val_loss: 1.5974 - val_accuracy: 0.6601 - val_sparse_top_k_categorical_accuracy: 0.9373\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.4415 - accuracy: 0.8643 - sparse_top_k_categorical_accuracy: 0.9895 - val_loss: 1.5696 - val_accuracy: 0.6700 - val_sparse_top_k_categorical_accuracy: 0.9307.8616 - sparse_top_k_cate\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 27s 207ms/step - loss: 0.3997 - accuracy: 0.8745 - sparse_top_k_categorical_accuracy: 0.9895 - val_loss: 1.5229 - val_accuracy: 0.6865 - val_sparse_top_k_categorical_accuracy: 0.9323\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 27s 207ms/step - loss: 0.3550 - accuracy: 0.8881 - sparse_top_k_categorical_accuracy: 0.9933 - val_loss: 1.5924 - val_accuracy: 0.6799 - val_sparse_top_k_categorical_accuracy: 0.9307\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 27s 207ms/step - loss: 0.3511 - accuracy: 0.8874 - sparse_top_k_categorical_accuracy: 0.9938 - val_loss: 1.7282 - val_accuracy: 0.6683 - val_sparse_top_k_categorical_accuracy: 0.9356\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.3395 - accuracy: 0.8919 - sparse_top_k_categorical_accuracy: 0.9929 - val_loss: 1.5765 - val_accuracy: 0.6931 - val_sparse_top_k_categorical_accuracy: 0.94060 -\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 27s 207ms/step - loss: 0.3187 - accuracy: 0.8957 - sparse_top_k_categorical_accuracy: 0.9943 - val_loss: 1.7109 - val_accuracy: 0.6700 - val_sparse_top_k_categorical_accuracy: 0.9257\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 27s 207ms/step - loss: 0.2773 - accuracy: 0.9078 - sparse_top_k_categorical_accuracy: 0.9983 - val_loss: 1.7278 - val_accuracy: 0.6848 - val_sparse_top_k_categorical_accuracy: 0.9389\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 28s 209ms/step - loss: 0.3058 - accuracy: 0.9033 - sparse_top_k_categorical_accuracy: 0.9964 - val_loss: 1.8507 - val_accuracy: 0.6700 - val_sparse_top_k_categorical_accuracy: 0.9373\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.2669 - accuracy: 0.9187 - sparse_top_k_categorical_accuracy: 0.9967 - val_loss: 1.6407 - val_accuracy: 0.6865 - val_sparse_top_k_categorical_accuracy: 0.9406\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.2863 - accuracy: 0.9092 - sparse_top_k_categorical_accuracy: 0.9964 - val_loss: 1.6390 - val_accuracy: 0.6650 - val_sparse_top_k_categorical_accuracy: 0.9257\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.2530 - accuracy: 0.9218 - sparse_top_k_categorical_accuracy: 0.9962 - val_loss: 1.7285 - val_accuracy: 0.6749 - val_sparse_top_k_categorical_accuracy: 0.9290\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 28s 209ms/step - loss: 0.2337 - accuracy: 0.9251 - sparse_top_k_categorical_accuracy: 0.9976 - val_loss: 1.6554 - val_accuracy: 0.6865 - val_sparse_top_k_categorical_accuracy: 0.9340\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 28s 209ms/step - loss: 0.2086 - accuracy: 0.9323 - sparse_top_k_categorical_accuracy: 0.9983 - val_loss: 1.9366 - val_accuracy: 0.6650 - val_sparse_top_k_categorical_accuracy: 0.9241\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 28s 209ms/step - loss: 0.1971 - accuracy: 0.9337 - sparse_top_k_categorical_accuracy: 0.9981 - val_loss: 2.0046 - val_accuracy: 0.6782 - val_sparse_top_k_categorical_accuracy: 0.9323\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 27s 207ms/step - loss: 0.2021 - accuracy: 0.9358 - sparse_top_k_categorical_accuracy: 0.9983 - val_loss: 1.7591 - val_accuracy: 0.6865 - val_sparse_top_k_categorical_accuracy: 0.9274\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.1885 - accuracy: 0.9382 - sparse_top_k_categorical_accuracy: 0.9981 - val_loss: 1.7696 - val_accuracy: 0.6964 - val_sparse_top_k_categorical_accuracy: 0.9389\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.1902 - accuracy: 0.9437 - sparse_top_k_categorical_accuracy: 0.9983 - val_loss: 1.7786 - val_accuracy: 0.6716 - val_sparse_top_k_categorical_accuracy: 0.9323\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 27s 207ms/step - loss: 0.1768 - accuracy: 0.9482 - sparse_top_k_categorical_accuracy: 0.9990 - val_loss: 1.7234 - val_accuracy: 0.7013 - val_sparse_top_k_categorical_accuracy: 0.9274\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 27s 208ms/step - loss: 0.1708 - accuracy: 0.9442 - sparse_top_k_categorical_accuracy: 0.9983 - val_loss: 1.7511 - val_accuracy: 0.7096 - val_sparse_top_k_categorical_accuracy: 0.9356\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.1447 - accuracy: 0.9546 - sparse_top_k_categorical_accuracy: 0.9983 - val_loss: 1.9141 - val_accuracy: 0.6865 - val_sparse_top_k_categorical_accuracy: 0.9290\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.1370 - accuracy: 0.9565 - sparse_top_k_categorical_accuracy: 0.9995 - val_loss: 2.0153 - val_accuracy: 0.6766 - val_sparse_top_k_categorical_accuracy: 0.9307\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.1390 - accuracy: 0.9553 - sparse_top_k_categorical_accuracy: 0.9988 - val_loss: 2.1120 - val_accuracy: 0.6650 - val_sparse_top_k_categorical_accuracy: 0.9175\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.1582 - accuracy: 0.9572 - sparse_top_k_categorical_accuracy: 0.9983 - val_loss: 1.8648 - val_accuracy: 0.6947 - val_sparse_top_k_categorical_accuracy: 0.9373\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.1366 - accuracy: 0.9558 - sparse_top_k_categorical_accuracy: 0.9995 - val_loss: 1.9801 - val_accuracy: 0.6782 - val_sparse_top_k_categorical_accuracy: 0.9373\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.1042 - accuracy: 0.9670 - sparse_top_k_categorical_accuracy: 0.9990 - val_loss: 2.2239 - val_accuracy: 0.6914 - val_sparse_top_k_categorical_accuracy: 0.9340\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 27s 207ms/step - loss: 0.1422 - accuracy: 0.9579 - sparse_top_k_categorical_accuracy: 0.9983 - val_loss: 2.2143 - val_accuracy: 0.6683 - val_sparse_top_k_categorical_accuracy: 0.9224\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.1417 - accuracy: 0.9560 - sparse_top_k_categorical_accuracy: 0.9995 - val_loss: 2.1162 - val_accuracy: 0.6667 - val_sparse_top_k_categorical_accuracy: 0.9307\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.1192 - accuracy: 0.9653 - sparse_top_k_categorical_accuracy: 0.9993 - val_loss: 2.1669 - val_accuracy: 0.6799 - val_sparse_top_k_categorical_accuracy: 0.9175_k_categorical_accuracy: 0.\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 27s 207ms/step - loss: 0.0984 - accuracy: 0.9693 - sparse_top_k_categorical_accuracy: 0.9995 - val_loss: 2.1264 - val_accuracy: 0.6881 - val_sparse_top_k_categorical_accuracy: 0.9257\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.0943 - accuracy: 0.9715 - sparse_top_k_categorical_accuracy: 0.9998 - val_loss: 2.2088 - val_accuracy: 0.6733 - val_sparse_top_k_categorical_accuracy: 0.92240859 - ac - ETA: 3s - loss: 0.0927 - accuracy: 0.9709 - spa\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.0946 - accuracy: 0.9677 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 2.1605 - val_accuracy: 0.6766 - val_sparse_top_k_categorical_accuracy: 0.9274\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.0969 - accuracy: 0.9705 - sparse_top_k_categorical_accuracy: 0.9993 - val_loss: 2.1943 - val_accuracy: 0.6716 - val_sparse_top_k_categorical_accuracy: 0.9208\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.0870 - accuracy: 0.9720 - sparse_top_k_categorical_accuracy: 0.9993 - val_loss: 2.1921 - val_accuracy: 0.6799 - val_sparse_top_k_categorical_accuracy: 0.9241\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 27s 208ms/step - loss: 0.0959 - accuracy: 0.9703 - sparse_top_k_categorical_accuracy: 0.9995 - val_loss: 2.0511 - val_accuracy: 0.6865 - val_sparse_top_k_categorical_accuracy: 0.9323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b31da6f3b80>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrain model\n",
    "train_ds = tf.data.TextLineDataset('train_with_labeled_data.txt') \n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "train_ds = configure_for_performance(train_ds)\n",
    "\n",
    "model.fit(train_ds,validation_data=val_ds,epochs=50,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpPs4SWetAo4"
   },
   "source": [
    "# Output submission csv for Kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "sV2YebpItAo4"
   },
   "outputs": [],
   "source": [
    "with open('submission_task2_semisupervised.csv', 'w') as f:\n",
    "  f.write('id,predicted\\n')\n",
    "  for image_batch, image_names in test_ds:\n",
    "    predictions = model.predict(image_batch)\n",
    "    for image_name, predictions in zip(image_names.numpy(), model.predict(image_batch)):\n",
    "      inds = np.argmax(predictions)\n",
    "      line = str(int(image_name)) + ',' + class_names[inds]\n",
    "      f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xt7OaOehvoh1"
   },
   "source": [
    "**Note**\n",
    "\n",
    "Absolute path is recommended here. For example, use \"/projectnb2/cs542-bap/[your directory name]/submission_task1_supervised.csv\" to replace \"submission_task1_supervised.csv\".\n",
    "\n",
    "Besides, you can request good resources by specify the type of gpus, such as \"qsub -l gpus=1 -l gpu_type=P100 [your file name].qsub\". This is helpful to avoid potential issues of GPUs, such as out of memory, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g7aizvesi_kt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "baselineModel_task1 (1).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
